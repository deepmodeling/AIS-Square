# Paper

SPICE 数据集全称 Small-Molecule/Protein Interaction Chemical Energies

**[https://www.nature.com/articles/s41597-022-01882-6](https://www.nature.com/articles/s41597-022-01882-6)**

**暂时无法在飞书文档外展示此内容**

# Code Availability

Github 仓库只包含了SPICE 数据集创建过程中所需要的脚本与数据文件，并不包含 SPICE 数据集本身。

**[https://github.com/openmm/spice-dataset](https://github.com/openmm/spice-dataset)**

SPICE 数据集大小为 10GB+，故而难以在RAM中直接打开这么大的文件，采用HDF5格式存储。

**[https://zenodo.org/record/7606550#.Y-3koi-KFhE](https://zenodo.org/record/7606550#.Y-3koi-KFhE)**

详细数据结构与子见上下两个链接，注意update到最新版本

# 关于HDF5数据格式

[HDF5](https://link.zhihu.com/?target=https%3A//www.hdfgroup.org/solutions/hdf5/) (Hierarchical Data Format) 由美国伊利诺伊大学厄巴纳-香槟分校 [UIUC](https://link.zhihu.com/?target=http%3A//www.illinois.edu/) (University of Illinois at Urbana-Champaign) 开发，是一种常见的跨平台数据储存文件，可以存储不同类型的图像和数码数据，并且可以在不同类型的机器上传输，同时还有统一处理这种文件格式的函数库。**DeepMD原生支持HDF5：**

**[https://docs.deepmodeling.com/projects/deepmd/en/master/data/data-conv.html#hdf5-format](https://docs.deepmodeling.com/projects/deepmd/en/master/data/data-conv.html#hdf5-format)**

HDF5 文件一般以 .h5 或者 .hdf5 作为后缀名，需要专门的软件才能打开预览文件的内容。HDF5文件结构中有 2 primary objects: Groups 和 Datasets。

* Groups 就类似于文件夹，每个 HDF5 文件其实就是根目录 (root) group `'/'`。
* Datasets 类似于 [NumPy](https://link.zhihu.com/?target=https%3A//numpy.org/) 中的数组 array

```JSON
+-- /
|   +-- group_1
|   |   +-- dataset_1_1
|   |   |   +-- attribute_1_1_1
|   |   |   +-- attribute_1_1_2
|   |   |   +-- ...
|   |   |
|   |   +-- dataset_1_2
|   |   |   +-- attribute_1_2_1
|   |   |   +-- attribute_1_2_2
|   |   |   +-- ...
|   |   |
|   |   +-- ...
|   |
|   +-- group_2
|   |   +-- dataset_2_1
|   |   |   +-- attribute_2_1_1
|   |   |   +-- attribute_2_1_2
|   |   |   +-- ...|   |   |
|   |   +-- dataset_2_2
|   |   |   +-- attribute_2_2_1
|   |   |   +-- attribute_2_2_2
|   |   |   +-- ...
|   |   |
|   |   +-- ...
|   |
|   +-- ...
```

每个 dataset 可以分成两部分: 原始数据 (raw) data values 和 元数据 metadata (a set of data that describes and gives information about other data => raw data)。

```Java
+-- Dataset
|   +-- (Raw) Data Values (eg: a 4 x 5 x 6 matrix)
|   +-- Metadata
|   |   +-- Dataspace (eg: Rank = 3, Dimensions = {4, 5, 6})
|   |   +-- Datatype (eg: Integer)
|   |   +-- Properties (eg: Chuncked, Compressed)
|   |   +-- Attributes (eg: attr1 = 32.4, attr2 = "hello", ...)
```

从上面的结构中可以看出：

* Dataspace 给出原始数据的秩 (Rank) 和维度 (dimension)
* Datatype 给出数据类型
* Properties 说明该 dataset 的分块储存以及压缩情况
  * Chunked: Better access time for subsets; extendible
  * Chunked & Compressed: Improves storage efficiency, transmission speed
* Attributes 为该 dataset 的其他自定义属性

# dpdata

在搜集信息的初期我尝试用dpdata进行转换，后来发现hdf5只是一种存储形式（譬如文件夹）而不是一种数据格式（譬如.raw，.npy），DeepMD原生支持hdf5，也就是说我们在input.json中在.hdf5后加#号直接填路径即可接着访问下方的目录）

也就是说只是把文件夹换了中wrap up方式

# 数据集结构

这里我用python的h5py包进行处理操作：

整个根目录下包含了若干Group（可以理解为文件夹，或者说一个对应于deepmd数据中的一个system

![](https://dptechnology.feishu.cn/space/api/box/stream/download/asynccode/?code=ZGEyYWEzMTI4YzI2YjMxZjE5OGUyNjIzZjc2NmJhNTNfTGdldE41UDRkVmtVcVhPRmFZaFY3OFp4bTZOQUFVRjdfVG9rZW46Ym94Y25MQkxKQ2JWUllwMnhZSmI4ZlQwNkVjXzE2Nzk1ODQ5Mjg6MTY3OTU4ODUyOF9WNA)

每个文件夹下面的第二级已经只包含以物理量命名的datasets，参考numpy中的array，或者说是.npy文件

![](https://dptechnology.feishu.cn/space/api/box/stream/download/asynccode/?code=NTRjOTRhZDdhNDNiOTI4ZjY5ZTk3ODIyY2Q3NTMwMTFfOW1RSlk3VWRCWDVwbVlic3RKbFNCMGlKWDNPQUFTVG5fVG9rZW46Ym94Y250MzJIdnBMOWw3dmROVlY2NkZmMDVlXzE2Nzk1ODQ5Mjg6MTY3OTU4ODUyOF9WNA)

每个dataset（理解成.npy文件）的物理含义如下

![](https://dptechnology.feishu.cn/space/api/box/stream/download/asynccode/?code=NzBiZGMyODQ3ZmViZjRhODRhNzMwMjBlMmQ4ZjYyNzdfQkQ3dzd4VzBrdmtFdHgxbVY0RzVWb3U5M0tjZVBJRUdfVG9rZW46Ym94Y25wS1BtUFg5MG9rVktVNHRjMGQzZmRLXzE2Nzk1ODQ5Mjg6MTY3OTU4ODUyOF9WNA)

atomic_numbers 填写的是原子序数，我们经过重新映射

map_dict = {1: 0, 3: 1, 6: 2, 7: 3, 8: 4, 9: 5, 11: 6, 12: 7, 15: 8, 16: 9, 17: 10, 19: 11, 20: 12, 35: 13, 53: 14}

type_map = np.array(['H', 'Li', 'C', 'N', 'O', 'F', 'Na', 'Mg', 'P', 'S', 'Cl', 'K', 'Ca', 'Br', 'I'])

就可以得到 type.raw

dft_total_energy -> energy.npy 注意Hartree 转 eV 1 Hartree energy = 27.2114079527 eV

conformations -> coord.npy 注意Bohr 转 A 1 b, a.u. = 0.529177249 A

dft_total_gradient * (-1) -> force.npy 注意Hartree/Bohr 转 eV/A

scf_dipoles -> dipole.npy

mbis_dipoles -> atomic_dipole.npy

我们只需要加上nopbc就可以诶不用填写box.npy

![](https://dptechnology.feishu.cn/space/api/box/stream/download/asynccode/?code=NDVlYWZiZDU3OTI3NjRmNmViMjE5ZTU5OGMyNDVlY2RfcnJDY3BNbDNXTFBZaVZXMGk0T1dRUEFiaGxYZUx1cjhfVG9rZW46Ym94Y25YbElIM0dsTnpjdG5TRkphS3JicU5kXzE2Nzk1ODQ5Mjg6MTY3OTU4ODUyOF9WNA)

目前我能做的是将所有dataset转换成了.npy文件并按照映射规则重命名，也就是说把每个一级目录都变成了一个system可以填写在input.json的路径中（.hdf5后加上#号接着填group即可），用于直接训练，数据集脚本如下：

```Python
import h5py
import pathlib
import numpy as np
import os
spice = h5py.File("SPICE-1.1.3.hdf5", 'r')
number = 0
for index in spice.keys():
    system = spice[index]
    type_map = np.array(['H', 'Li', 'C', 'N', 'O', 'F', 'Na',
                         'Mg', 'P', 'S', 'Cl', 'K', 'Ca', 'Br', 'I'])
    map_dict = {1: 0, 3: 1, 6: 2, 7: 3, 8: 4, 9: 5, 11: 6, 12: 7,
                15: 8, 16: 9, 17: 10, 19: 11, 20: 12, 35: 13, 53: 14}
    original_type = np.array(system['atomic_numbers'])
    type = np.array([map_dict[i] for i in original_type])
    subset_list = np.array(['Dipeptides', 'Solvated Amino Acids',
                        'DES370K', 'DES Monomers', 'PubChem', 'Ion Pairs'])
    subset = np.array(system['subset'])
    for i in subset_list:
        if i in str(subset[0]):
            subset = i
    energy = 27.2114079527 * np.array(system['dft_total_energy'])
    force = - 27.2114079527/0.529177249 * np.array(system['dft_total_gradient'])
    force = force.reshape(force.shape[0], force.shape[1]*3)
    coord = 0.529177249 * np.array(system['conformations'])
    coord = coord.reshape(coord.shape[0], coord.shape[1]*3)
    if 'mbis_dipoles' in system.keys():
        atomic_dipole = np.array(system['mbis_dipoles'])
        atomic_dipole = atomic_dipole.reshape(atomic_dipole.shape[0], atomic_dipole.shape[1]*3)
    if 'scf_dipole' in system.keys():   
        dipole = np.array(system['scf_dipole'])
  
    # 这里需要把路径换成自己的
    dir = os.path.join('/Users/AntiEntropy/SPICE-1.1.3/data', subset, 'sys.'+ '%.6d'%number)
    pathlib.Path(dir).mkdir(parents=True, exist_ok=True)
    set = os.path.join(dir, 'set.000')
    pathlib.Path(set).mkdir(parents=True, exist_ok=True)
    np.save(os.path.join(set, 'energy.npy'), energy)
    np.save(os.path.join(set, 'coord.npy'), coord)
    np.save(os.path.join(set, 'force.npy'), force)
    if 'scf_dipole' in system.keys():
        np.save(os.path.join(set, 'dipole.npy'), dipole)
    if 'mbis_dipoles' in system.keys():
        np.save(os.path.join(set, 'atomic_dipole.npy'), atomic_dipole)
    file1 = open(os.path.join(dir, 'type_map.raw'), 'w')
    for i in type_map:
        file1.write(i + '\n')
    file1.close()
    file2 = open(os.path.join(dir, 'type.raw'), 'w')
    for i in type:
        file2.write(str(i) + '\n')
    file2.close()
    file3 = open(os.path.join(dir, 'nopbc'), 'w')
    file3.close()
    number += 1
```

接下来我会继续尝试把这个脚本用dpdata的from和to接口打包起来，争取可以pip install，**做成HDF5向dpdata支持的HDF5结构通用的转化模式。**

# 区分电荷的新type_maph和type.raw

![](https://dptechnology.feishu.cn/space/api/box/stream/download/asynccode/?code=N2MwNDExOTBmMzNjNzkxZjFkOTZkZGI4MmUzYjJhMmFfMFNxck4zOGJUSHBmZUhyNUxwaUR3dmZSZFJic0tCbmJfVG9rZW46Ym94Y25Mcm1URHlkd3hHdjJvWnFBREhRMlVjXzE2Nzk1ODQ5Mjg6MTY3OTU4ODUyOF9WNA)

 type_map = np.array(['H', 'Li+', 'C-', 'C', 'C+', 'N-', 'N', 'N+', 'O-', 'O', 'O+', 'F-', 'F', 'Na+',
                         'Mg+2', 'P', 'P+', 'S-', 'S', 'S+', 'Cl-', 'Cl', 'K+', 'Ca+2', 'Br-', 'Br', 'I-', 'I'])

```Python
import os
import h5py
import pathlib
import numpy as np
from tqdm import tqdm

spice = h5py.File("SPICE-1.1.3.hdf5", 'r')
number = 0
for index in tqdm(spice.keys()):
    system = spice[index]
    type_map = np.array(['H', 'Li+', 'C-', 'C', 'C+', 'N-', 'N', 'N+', 'O-', 'O', 'O+', 'F-', 'F', 'Na+',
                         'Mg+2', 'P', 'P+', 'S-', 'S', 'S+', 'Cl-', 'Cl', 'K+', 'Ca+2', 'Br-', 'Br', 'I-', 'I'])
    map_dict = {1: 0, 3: 1, 6: 3, 7: 6, 8: 9, 9: 12, 11: 13, 12: 14,
                15: 15, 16: 18, 17: 21, 19: 22, 20: 23, 35: 25, 53: 27}
    map_dict_charge = {1: 0, 3: 1, 6: [2,3,4], 7: [5,6,7], 8: [8,9,10], 9: [11,12], 11: 13, 12: 14,
                15: [15,16], 16: [17,18,19], 17:[20,21], 19: 22, 20: 23, 35: [24,25], 53: [26,27]}
    atomic_number = np.array(system['atomic_numbers'])
    type = []
    element = []
    SMILES = str(np.array(system['smiles'])[0])[2:-1]
    count = 0
    for i in range(1, len(atomic_number)+1):
        loc = SMILES.find(':'+ str(i)+']')
        raw = SMILES[max(loc-4,0):loc]
        ion = raw.lstrip('+-0123456789][/()=.@#\\')
        ion = ion.replace("@",'')
        ion = ion.strip("][/()=.@#\\")
        ion = ion.lstrip('+-0123456789][/()=.@#\\')
        ion = ion.replace('h','H')
        ion = ion.replace('c','C')
        ion = ion.replace('n','N')
        ion = ion.replace('o','O')
        element.append(ion)
        type.append(list(type_map).index(ion))
        count +=1

    element = np.array(element)
    type = np.array(type)
  
    subset_list = np.array(['Dipeptides', 'Solvated Amino Acids',
                        'DES370K', 'DES Monomers', 'PubChem', 'Ion Pairs'])
    subset = np.array(system['subset'])
    for i in subset_list:
        if i in str(subset[0]):
            subset = i
    energy = 27.2114079527 * np.array(system['dft_total_energy'])
    force = - 27.2114079527/0.529177249 * np.array(system['dft_total_gradient'])
    force = force.reshape(force.shape[0], force.shape[1]*3)
    coord = 0.529177249 * np.array(system['conformations'])
    coord = coord.reshape(coord.shape[0], coord.shape[1]*3)
    if 'mbis_dipoles' in system.keys():
        atomic_dipole = np.array(system['mbis_dipoles'])
        atomic_dipole = atomic_dipole.reshape(atomic_dipole.shape[0], atomic_dipole.shape[1]*3)
    if 'scf_dipole' in system.keys():   
        dipole = np.array(system['scf_dipole'])
  
    dir = os.path.join('/Users/AntiEntropy/Documents/Code/DPA/spice/SPICE-1.1.3/data', subset, 'sys.'+ '%.6d'%number)
    pathlib.Path(dir).mkdir(parents=True, exist_ok=True)
    set = os.path.join(dir, 'set.000')
    pathlib.Path(set).mkdir(parents=True, exist_ok=True)
    np.save(os.path.join(set, 'energy.npy'), energy)
    np.save(os.path.join(set, 'coord.npy'), coord)
    np.save(os.path.join(set, 'force.npy'), force)
    if 'scf_dipole' in system.keys():
        np.save(os.path.join(set, 'dipole.npy'), dipole)
    if 'mbis_dipoles' in system.keys():
        np.save(os.path.join(set, 'atomic_dipole.npy'), atomic_dipole)
    file1 = open(os.path.join(dir, 'type_map.raw'), 'w')
    for i in type_map:
        file1.write(i + '\n')
    file1.close()
    file2 = open(os.path.join(dir, 'type.raw'), 'w')
    for i in type:
        file2.write(str(i) + '\n')
    file2.close()
    file3 = open(os.path.join(dir, 'nopbc'), 'w')
    file3.close()
    number += 1
```
